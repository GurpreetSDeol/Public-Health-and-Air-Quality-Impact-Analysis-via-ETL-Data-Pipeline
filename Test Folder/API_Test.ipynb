{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json \n",
    "import pandas as pd \n",
    "import time\n",
    "import pycountry\n",
    "from json_flatten import flatten\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "from timezonefinder import TimezoneFinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "OW_api_key = '1bb3d74b03e16c97feaddad9963cd29d'\n",
    "Nin_api_key = 'moIsb6GGrVPEVN0UzWFQhA==HLX28kq15hgK6EcC'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalise List of Cities to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_ranking = pd.read_csv(rf'C:\\Users\\gurpr\\OneDrive\\Documents\\New Projects\\Weather and Pollution\\Data\\Raw\\world-city-listing-table.csv')\n",
    "\n",
    "\n",
    "pop_ranking = pop_ranking[pop_ranking['population']>4000000]\n",
    "\n",
    "def country_to_iso_alpha2(country_name):\n",
    "    try:\n",
    "        return pycountry.countries.lookup(country_name).alpha_2\n",
    "    except LookupError:\n",
    "        return None  \n",
    "pop_ranking['country_iso'] = pop_ranking['country'].apply(country_to_iso_alpha2)\n",
    "\n",
    "countries = set(pop_ranking[\"country\"])\n",
    "cities = pop_ranking[['city','country_iso']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "City Lon and Lat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_coord = []\n",
    "delay = 2\n",
    "\n",
    "#cities = cities[1:2]\n",
    "\n",
    "for index, row in cities.iterrows():\n",
    "    city = row['city']\n",
    "    country = row['country_iso']\n",
    "\n",
    "    api_url = f'https://api.api-ninjas.com/v1/city?name={city}&country={country}&min_population=4500000'\n",
    "    response = requests.get(api_url , headers={'X-Api-Key': Nin_api_key})\n",
    "    if response.status_code == requests.codes.ok:\n",
    "        \n",
    "        cities_coord.append(response.text)\n",
    "        time.sleep(delay)\n",
    "    else:\n",
    "        print(\"Error:\", response.status_code, response.text)\n",
    "print(cities_coord)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Tokyo', 'latitude': 35.6897, 'longitude': 139.692, 'country': 'JP', 'population': 37977000, 'is_capital': True}, {'name': 'Delhi', 'latitude': 28.66, 'longitude': 77.23, 'country': 'IN', 'population': 29617000, 'is_capital': False}, {'name': 'Shanghai', 'latitude': 31.1667, 'longitude': 121.467, 'country': 'CN', 'population': 22120000, 'is_capital': False}, {'name': 'Dhaka', 'latitude': 23.7161, 'longitude': 90.3961, 'country': 'BD', 'population': 15443000, 'is_capital': True}, {'name': 'Sao Paulo', 'latitude': -23.5504, 'longitude': -46.6339, 'country': 'BR', 'population': 22046000, 'is_capital': False}, {'name': 'Cairo', 'latitude': 30.0561, 'longitude': 31.2394, 'country': 'EG', 'population': 19372000, 'is_capital': True}, {'name': 'Mexico City', 'latitude': 19.4333, 'longitude': -99.1333, 'country': 'MX', 'population': 20996000, 'is_capital': True}, {'name': 'Beijing', 'latitude': 39.905, 'longitude': 116.391, 'country': 'CN', 'population': 19433000, 'is_capital': True}, {'name': 'Mumbai', 'latitude': 18.9667, 'longitude': 72.8333, 'country': 'IN', 'population': 23355000, 'is_capital': False}, {'name': 'Osaka', 'latitude': 34.6936, 'longitude': 135.502, 'country': 'JP', 'population': 14977000, 'is_capital': False}, {'name': 'Chongqing', 'latitude': 29.55, 'longitude': 106.507, 'country': 'CN', 'population': 7739000, 'is_capital': False}, {'name': 'Karachi', 'latitude': 24.86, 'longitude': 67.01, 'country': 'PK', 'population': 14835000, 'is_capital': False}, {'name': 'Lagos', 'latitude': 6.45, 'longitude': 3.4, 'country': 'NG', 'population': 15279000, 'is_capital': False}, {'name': 'Buenos Aires', 'latitude': -34.5997, 'longitude': -58.3819, 'country': 'AR', 'population': 16157000, 'is_capital': True}, {'name': 'Kolkata', 'latitude': 22.5411, 'longitude': 88.3378, 'country': 'IN', 'population': 17560000, 'is_capital': False}, {'name': 'Manila', 'latitude': 14.5958, 'longitude': 120.977, 'country': 'PH', 'population': 23088000, 'is_capital': True}, {'name': 'Guangzhou', 'latitude': 23.1288, 'longitude': 113.259, 'country': 'CN', 'population': 20902000, 'is_capital': False}, {'name': 'Tianjin', 'latitude': 39.1467, 'longitude': 117.206, 'country': 'CN', 'population': 10800000, 'is_capital': False}, {'name': 'Lahore', 'latitude': 31.5497, 'longitude': 74.3436, 'country': 'PK', 'population': 11021000, 'is_capital': False}, {'name': 'Bangalore', 'latitude': 12.9699, 'longitude': 77.598, 'country': 'IN', 'population': 13707000, 'is_capital': False}, {'name': 'Rio De Janeiro', 'latitude': -22.9083, 'longitude': -43.1964, 'country': 'BR', 'population': 12272000, 'is_capital': False}, {'name': 'Shenzhen', 'latitude': 22.535, 'longitude': 114.054, 'country': 'CN', 'population': 15929000, 'is_capital': False}, {'name': 'Chennai', 'latitude': 13.0825, 'longitude': 80.275, 'country': 'IN', 'population': 11324000, 'is_capital': False}, {'name': 'Bogota', 'latitude': 4.6126, 'longitude': -74.0705, 'country': 'CO', 'population': 9464000, 'is_capital': True}, {'name': 'Jakarta', 'latitude': -6.2146, 'longitude': 106.845, 'country': 'ID', 'population': 34540000, 'is_capital': True}, {'name': 'Lima', 'latitude': -12.05, 'longitude': -77.0333, 'country': 'PE', 'population': 9848000, 'is_capital': True}, {'name': 'Paris', 'latitude': 48.8566, 'longitude': 2.3522, 'country': 'FR', 'population': 11020000, 'is_capital': True}, {'name': 'Bangkok', 'latitude': 13.75, 'longitude': 100.517, 'country': 'TH', 'population': 17066000, 'is_capital': True}, {'name': 'Hyderabad', 'latitude': 17.3667, 'longitude': 78.4667, 'country': 'IN', 'population': 9746000, 'is_capital': False}, {'name': 'Seoul', 'latitude': 37.5833, 'longitude': 127.0, 'country': 'KR', 'population': 21794000, 'is_capital': True}, {'name': 'Nanjing', 'latitude': 32.05, 'longitude': 118.767, 'country': 'CN', 'population': 7496000, 'is_capital': False}, {'name': 'Chengdu', 'latitude': 30.6636, 'longitude': 104.067, 'country': 'CN', 'population': 11309000, 'is_capital': False}, {'name': 'London', 'latitude': 51.5072, 'longitude': -0.1275, 'country': 'GB', 'population': 10979000, 'is_capital': True}, {'name': 'Luanda', 'latitude': -8.8383, 'longitude': 13.2344, 'country': 'AO', 'population': 8417000, 'is_capital': True}, {'name': 'Tehran', 'latitude': 35.7, 'longitude': 51.4167, 'country': 'IR', 'population': 13633000, 'is_capital': True}, {'name': 'Ho Chi Minh City', 'latitude': 10.8167, 'longitude': 106.633, 'country': 'VN', 'population': 13312000, 'is_capital': False}, {'name': 'Nagoya', 'latitude': 35.1167, 'longitude': 136.933, 'country': 'JP', 'population': 9113000, 'is_capital': False}, {'name': 'Wuhan', 'latitude': 30.5872, 'longitude': 114.288, 'country': 'CN', 'population': 8962000, 'is_capital': False}, {'name': 'Kuala Lumpur', 'latitude': 3.1478, 'longitude': 101.695, 'country': 'MY', 'population': 8285000, 'is_capital': True}, {'name': 'Hangzhou', 'latitude': 30.25, 'longitude': 120.168, 'country': 'CN', 'population': 6446000, 'is_capital': False}, {'name': 'Suzhou', 'latitude': 33.6333, 'longitude': 116.968, 'country': 'CN', 'population': 5690000, 'is_capital': False}, {'name': 'Surat', 'latitude': 21.17, 'longitude': 72.83, 'country': 'IN', 'population': 5807000, 'is_capital': False}, {'name': 'Dar Es Salaam', 'latitude': -6.8, 'longitude': 39.2833, 'country': 'TZ', 'population': 6698000, 'is_capital': True}, {'name': 'Baghdad', 'latitude': 33.35, 'longitude': 44.4167, 'country': 'IQ', 'population': 5796000, 'is_capital': True}, {'name': 'Shenyang', 'latitude': 41.8039, 'longitude': 123.426, 'country': 'CN', 'population': 7105000, 'is_capital': False}, {'name': 'Riyadh', 'latitude': 24.65, 'longitude': 46.71, 'country': 'SA', 'population': 6881000, 'is_capital': True}, {'name': 'Hong Kong', 'latitude': 22.305, 'longitude': 114.185, 'country': 'HK', 'population': 7347000, 'is_capital': False}, {'name': 'Foshan', 'latitude': 23.0292, 'longitude': 113.106, 'country': 'CN', 'population': 7194311, 'is_capital': False}, {'name': 'Dongguan', 'latitude': 23.0475, 'longitude': 113.749, 'country': 'CN', 'population': 7981000, 'is_capital': False}, {'name': 'Pune', 'latitude': 18.5196, 'longitude': 73.8553, 'country': 'IN', 'population': 7764000, 'is_capital': False}, {'name': 'Santiago', 'latitude': -33.45, 'longitude': -70.6667, 'country': 'CL', 'population': 7007000, 'is_capital': True}, {'name': 'Khartoum', 'latitude': 15.6031, 'longitude': 32.5265, 'country': 'SD', 'population': 7282000, 'is_capital': True}, {'name': 'Toronto', 'latitude': 43.7417, 'longitude': -79.3733, 'country': 'CA', 'population': 5429524, 'is_capital': False}, {'name': 'Belo Horizonte', 'latitude': -19.8917, 'longitude': -43.9478, 'country': 'BR', 'population': 5159000, 'is_capital': False}, {'name': 'Singapore', 'latitude': 1.3, 'longitude': 103.8, 'country': 'SG', 'population': 5745000, 'is_capital': True}, {'name': 'Qingdao', 'latitude': 36.1167, 'longitude': 120.4, 'country': 'CN', 'population': 5775000, 'is_capital': False}, {'name': 'Zhengzhou', 'latitude': 34.7492, 'longitude': 113.66, 'country': 'CN', 'population': 7005000, 'is_capital': False}, {'name': 'Barcelona', 'latitude': 41.3825, 'longitude': 2.1769, 'country': 'ES', 'population': 4588000, 'is_capital': False}, {'name': 'Alexandria', 'latitude': 31.2, 'longitude': 29.9167, 'country': 'EG', 'population': 4870000, 'is_capital': False}, {'name': 'Nairobi', 'latitude': -1.2864, 'longitude': 36.8172, 'country': 'KE', 'population': 5545000, 'is_capital': True}, {'name': 'Guadalajara', 'latitude': 20.6767, 'longitude': -103.348, 'country': 'MX', 'population': 5253000, 'is_capital': False}, {'name': 'Hanoi', 'latitude': 21.0245, 'longitude': 105.841, 'country': 'VN', 'population': 7785000, 'is_capital': True}, {'name': 'Melbourne', 'latitude': -37.8136, 'longitude': 144.963, 'country': 'AU', 'population': 5078193, 'is_capital': False}, {'name': 'Sydney', 'latitude': -33.865, 'longitude': 151.209, 'country': 'AU', 'population': 5312163, 'is_capital': False}, {'name': 'Changsha', 'latitude': 28.1987, 'longitude': 112.971, 'country': 'CN', 'population': 7044118, 'is_capital': False}, {'name': 'Kunming', 'latitude': 25.0433, 'longitude': 102.706, 'country': 'CN', 'population': 6250000, 'is_capital': False}, {'name': 'Changchun', 'latitude': 43.9, 'longitude': 125.2, 'country': 'CN', 'population': 7674439, 'is_capital': False}, {'name': 'Hefei', 'latitude': 31.8639, 'longitude': 117.281, 'country': 'CN', 'population': 7457027, 'is_capital': False}, {'name': 'Ningbo', 'latitude': 29.875, 'longitude': 121.549, 'country': 'CN', 'population': 7639000, 'is_capital': False}, {'name': 'Shantou', 'latitude': 23.3735, 'longitude': 116.694, 'country': 'CN', 'population': 5319028, 'is_capital': False}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "flattened_list = []\n",
    "\n",
    "for json_str in cities_coord:\n",
    "\n",
    "    list_of_dicts = json.loads(json_str)\n",
    "    \n",
    "    if isinstance(list_of_dicts, list):\n",
    "        flattened_list.extend(list_of_dicts)\n",
    "    else:\n",
    "        print(f\"Unexpected data format: {list_of_dicts}\")\n",
    "\n",
    "\n",
    "print(flattened_list)\n",
    "file_path = rf'C:\\Users\\gurpr\\OneDrive\\Documents\\New Projects\\Weather and Pollution\\Data\\Raw\\cities_geodata_list.json'\n",
    "\n",
    "with open(file_path, 'w') as f:\n",
    "    json.dump(flattened_list, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenWeather API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'C:\\Users\\gurpr\\OneDrive\\Documents\\New Projects\\Weather and Pollution\\Data\\Final'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m csv_save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mgurpr\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mNew Projects\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mWeather and Pollution\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mData\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mFinal\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mFinal_city_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      9\u001b[0m json_save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mgurpr\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mNew Projects\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mWeather and Pollution\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mData\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mFinal\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mFinal_city_data.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 10\u001b[0m \u001b[43mdata_to_csv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_save_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m city_data_json \u001b[38;5;241m=\u001b[39m data_to_csv\u001b[38;5;241m.\u001b[39mto_json(orient\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecords\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m city_data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(city_data_json)\n",
      "File \u001b[1;32mc:\\Users\\gurpr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gurpr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3965\u001b[0m )\n\u001b[1;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3984\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gurpr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\Users\\gurpr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32mc:\\Users\\gurpr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:749\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[1;32m--> 749\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[0;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    753\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gurpr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:616\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    614\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[0;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[1;32m--> 616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'C:\\Users\\gurpr\\OneDrive\\Documents\\New Projects\\Weather and Pollution\\Data\\Final'"
     ]
    }
   ],
   "source": [
    "file_path = rf'C:\\Users\\gurpr\\OneDrive\\Documents\\New Projects\\Weather and Pollution\\Data\\Raw\\cities_geodata_list.json'\n",
    "\n",
    "\n",
    "data_to_csv = pd.read_json(file_path)\n",
    "data_to_csv.rename(columns={'name': 'city_name'}, inplace=True)\n",
    "data_to_csv['city_id'] = pd.factorize(data_to_csv['city_name'])[0] + 1\n",
    "\n",
    "csv_save_path = rf'C:\\Users\\gurpr\\OneDrive\\Documents\\New Projects\\Weather and Pollution\\Data\\Final\\Final_city_data.csv'\n",
    "json_save_path = rf'C:\\Users\\gurpr\\OneDrive\\Documents\\New Projects\\Weather and Pollution\\Data\\Final\\Final_city_data.json'\n",
    "data_to_csv.to_csv(csv_save_path, index= False)\n",
    "\n",
    "city_data_json = data_to_csv.to_json(orient='records')\n",
    "city_data = json.loads(city_data_json)\n",
    "with open(json_save_path, 'w') as f:\n",
    "    json.dump(city_data, f, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "OW_weather_data = []\n",
    "OW_pollution_data = []\n",
    "delay = 2\n",
    "\n",
    "json_save_path = rf'D:\\Datasets\\Weather and Pollution\\Data\\Final\\Final_city_data.json'\n",
    "with open(json_save_path) as f:\n",
    "    city_data = json.load(f)\n",
    "\n",
    "city_data = city_data[:2]\n",
    "\n",
    "\n",
    "for city in city_data:\n",
    "\n",
    "     #Load the longitude and latitude data for each city\n",
    "     lat = city['latitude']\n",
    "     lon = city['longitude']\n",
    "     city_id = city['city_id']\n",
    "\n",
    "     #Fetch the current weather data \n",
    "     OW_weather_url = f'https://api.openweathermap.org/data/2.5/weather?lat={lat}&lon={lon}&appid={OW_api_key}'\n",
    "     response_weather = requests.get(OW_weather_url)\n",
    "     weather_data = response_weather.json()\n",
    "     weather_data['latitude'] = lat\n",
    "     weather_data['longitude'] = lon\n",
    "     weather_data['city_id'] = city_id\n",
    "     OW_weather_data.append(weather_data)\n",
    "     time.sleep(delay)\n",
    "\n",
    "     #Fetch the current air quality data\n",
    "     OW_pollution_url = f'http://api.openweathermap.org/data/2.5/air_pollution?lat={lat}&lon={lon}&appid={OW_api_key}'\n",
    "     response_pollution = requests.get(OW_pollution_url)\n",
    "     pollution_data = response_pollution.json()\n",
    "     pollution_data['latitude'] = lat\n",
    "     pollution_data['longitude'] = lon\n",
    "     pollution_data['city_id'] = city_id\n",
    "     OW_pollution_data.append(pollution_data)\n",
    "     time.sleep(delay)\n",
    "\n",
    "\n",
    "#Save each file \n",
    "OW_raw_weather_filepath = rf'C:\\Users\\gurpr\\OneDrive\\Documents\\New Projects\\Weather and Pollution\\Data\\Raw\\OW_raw_weather_data.json'\n",
    "with open(OW_raw_weather_filepath, 'w') as f:\n",
    "    json.dump(OW_weather_data, f, indent=4)\n",
    "\n",
    "OW_raw_pollution_filepath = rf'C:\\Users\\gurpr\\OneDrive\\Documents\\New Projects\\Weather and Pollution\\Data\\Raw\\OW_raw_pollution_data.json'\n",
    "with open(OW_raw_pollution_filepath, 'w') as f:\n",
    "    json.dump(OW_pollution_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rename_and_convert_columns(df, column_map):\n",
    "    \"\"\"\n",
    "    Renames columns in a DataFrame and converts them to the specified data types.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to process.\n",
    "        column_map (dict): A dictionary where keys are original column names and values are tuples of \n",
    "                           the new column name and data type (e.g., ('new_name', 'dtype')).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The modified DataFrame with renamed columns and converted data types.\n",
    "    \"\"\"\n",
    "    for original_col, (new_col, dtype) in column_map.items():\n",
    "        if original_col in df.columns:\n",
    "            df.rename(columns={original_col: new_col}, inplace=True)\n",
    "            \n",
    "            # Convert to appropriate data type\n",
    "            if dtype == 'float':\n",
    "                df[new_col] = pd.to_numeric(df[new_col], errors='coerce')\n",
    "            elif dtype == 'int':\n",
    "                df[new_col] = pd.to_numeric(df[new_col], errors='coerce', downcast='integer')\n",
    "            elif dtype == 'datetime':\n",
    "                # Explicitly cast to numeric before converting to datetime\n",
    "                df[new_col] = pd.to_datetime(pd.to_numeric(df[new_col], errors='coerce'), unit='s', errors='coerce')\n",
    "                df[new_col] = df[new_col].dt.round('H')\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_local_time(datetime_str, lat, lon):\n",
    "    \"\"\"\n",
    "    Calculates the local time based on latitude, longitude, and UK local datetime.\n",
    "\n",
    "    Parameters:\n",
    "    datetime_str (str): The datetime in UK local time as a string.\n",
    "    lat (float): Latitude of the location.\n",
    "    lon (float): Longitude of the location.\n",
    "\n",
    "    Returns:\n",
    "    pd.Timestamp: The local time as a Pandas Timestamp object.\n",
    "    \"\"\"\n",
    "  \n",
    "    # Parse the UK local datetime string into a datetime object\n",
    "    uk_datetime = pd.to_datetime(datetime_str)\n",
    "\n",
    "    # Initialize TimezoneFinder\n",
    "    tf = TimezoneFinder()\n",
    "\n",
    "    # Find timezone based on latitude and longitude\n",
    "    timezone_str = tf.timezone_at(lng=lon, lat=lat)\n",
    "\n",
    "    # Get the timezone\n",
    "    timezone = pytz.timezone(timezone_str)\n",
    "    # Convert the UK local time to local time in the identified timezone\n",
    "    local_time = pd.Timestamp(uk_datetime).tz_localize(pytz.timezone('Europe/London')).astimezone(timezone)\n",
    "    return local_time.tz_localize(None)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gurpr\\AppData\\Local\\Temp\\ipykernel_12032\\1439812154.py:25: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df[new_col] = df[new_col].dt.round('H')\n",
      "C:\\Users\\gurpr\\AppData\\Local\\Temp\\ipykernel_12032\\1439812154.py:25: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df[new_col] = df[new_col].dt.round('H')\n",
      "C:\\Users\\gurpr\\AppData\\Local\\Temp\\ipykernel_12032\\1439812154.py:25: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df[new_col] = df[new_col].dt.round('H')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city_id                          int8\n",
      "date_time              datetime64[ns]\n",
      "local_time             datetime64[ns]\n",
      "temperature                   float64\n",
      "feels_like                    float64\n",
      "temp_min                      float64\n",
      "temp_max                      float64\n",
      "pressure                        int16\n",
      "humidity                         int8\n",
      "visibility                      int16\n",
      "wind_speed                    float64\n",
      "wind_deg                        int16\n",
      "clouds_all                       int8\n",
      "weather_main                   object\n",
      "weather_description            object\n",
      "weather_icon                   object\n",
      "sunrise                datetime64[ns]\n",
      "sunset                 datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "OW_raw_weather_filepath = rf'C:\\Users\\gurpr\\OneDrive\\Documents\\New Projects\\Weather and Pollution\\Data\\Raw\\OW_raw_weather_data.json'\n",
    "\n",
    "with open(OW_raw_weather_filepath) as f:\n",
    "    raw_weather_data = json.load(f)\n",
    "flattened_weather_data = [flatten(item) for item in raw_weather_data]\n",
    "\n",
    "# Convert to DataFrame\n",
    "weather_data_df = pd.DataFrame(flattened_weather_data)\n",
    "\n",
    "# Define a mapping for column renaming and data type conversions\n",
    "weather_column_map = {\n",
    "    'city_id$int': ('city_id', 'int'),\n",
    "    'longitude$float': ('longitude', 'float'),\n",
    "    'latitude$float': ('latitude', 'float'),\n",
    "    'weather.[0].id$int': ('weather_id', 'int'),\n",
    "    'weather.[0].main': ('weather_main', 'str'),\n",
    "    'weather.[0].description': ('weather_description', 'str'),\n",
    "    'weather.[0].icon': ('weather_icon', 'str'),\n",
    "    'main.temp$float': ('temperature', 'float'),\n",
    "    'main.feels_like$float': ('feels_like', 'float'),\n",
    "    'main.temp_min$float': ('temp_min', 'float'),\n",
    "    'main.temp_max$float': ('temp_max', 'float'),\n",
    "    'main.pressure$int': ('pressure', 'int'),\n",
    "    'main.humidity$int': ('humidity', 'int'),\n",
    "    'main.sea_level$int': ('sea_level', 'int'),\n",
    "    'main.grnd_level$int': ('grnd_level', 'int'),\n",
    "    'visibility$int': ('visibility', 'int'),\n",
    "    'wind.speed$float': ('wind_speed', 'float'),\n",
    "    'wind.deg$int': ('wind_deg', 'int'),\n",
    "    'clouds.all$int': ('clouds_all', 'int'),\n",
    "    'dt$int': ('date_time', 'datetime'),\n",
    "    'sys.type$int': ('sys_type', 'int'),\n",
    "    'sys.id$int': ('sys_id', 'int'),\n",
    "    'sys.country': ('sys_country', 'str'),\n",
    "    'sys.sunrise$int': ('sunrise', 'datetime'),\n",
    "    'sys.sunset$int': ('sunset', 'datetime'),\n",
    "    'timezone$int': ('timezone', 'int'),\n",
    "    'id$int': ('id', 'int'),\n",
    "    'name': ('name', 'str'),\n",
    "    'cod$int': ('cod', 'int'),\n",
    "    'wind.gust$float': ('wind_gust', 'float'),\n",
    "    'rain.1h$float': ('rain_1h', 'float')\n",
    "}\n",
    "\n",
    "weather_data_df = rename_and_convert_columns(weather_data_df, weather_column_map)\n",
    "weather_data_df['local_time'] = weather_data_df.apply(\n",
    "    lambda row: calculate_local_time(row['date_time'], row['latitude'], row['longitude']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "\n",
    "# Define the columns to keep\n",
    "required_columns = [\n",
    "    'city_id',  'date_time', 'local_time','temperature', 'feels_like', 'temp_min', 'temp_max',\n",
    "    'pressure', 'humidity', 'visibility', 'wind_speed', 'wind_deg', 'clouds_all',\n",
    "    'weather_main', 'weather_description', 'weather_icon', 'sunrise', 'sunset'\n",
    "]\n",
    "\n",
    "\n",
    "# Filter DataFrame to keep only the required columns\n",
    "weather_data_df = weather_data_df[required_columns]\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "weather_data_df.to_csv('weather_data_df.csv', index=False)\n",
    "\n",
    "print(weather_data_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_uk_local_to_city_local(lat, lon, uk_local_time):\n",
    "    \"\"\"\n",
    "    Convert UK local time to the local time of a city based on latitude and longitude.\n",
    "    \n",
    "    Args:\n",
    "    - lat (float): Latitude of the city.\n",
    "    - lon (float): Longitude of the city.\n",
    "    - uk_local_time (datetime): A datetime object in UK local time (GMT/BST).\n",
    "    \n",
    "    Returns:\n",
    "    - local_time (datetime): The datetime converted to local time of the city.\n",
    "    \"\"\"\n",
    "    # Define the timezone for the UK and Convert UK local time to UTC\n",
    "    uk_timezone = pytz.timezone('Europe/London')\n",
    "    utc_time = uk_local_time.astimezone(pytz.utc)\n",
    "\n",
    "    # Determine the timezone based on latitude and longitude\n",
    "    tz_finder = tzwhere.tzwhere()\n",
    "    timezone_str = tz_finder.tzNameAt(lat, lon)\n",
    "\n",
    "    # Convert UTC time to local time\n",
    "    timezone = pytz.timezone(timezone_str)\n",
    "    local_time = utc_time.astimezone(timezone)\n",
    "    return local_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gurpr\\AppData\\Local\\Temp\\ipykernel_12032\\1439812154.py:25: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df[new_col] = df[new_col].dt.round('H')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city_id                 int8\n",
      "date_time     datetime64[ns]\n",
      "aqi                     int8\n",
      "co                   float64\n",
      "no2                  float64\n",
      "o3                   float64\n",
      "so2                  float64\n",
      "pm2_5                float64\n",
      "pm10                 float64\n",
      "nh3                  float64\n",
      "local_time    datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "OW_raw_pollution_filepath = rf'C:\\Users\\gurpr\\OneDrive\\Documents\\New Projects\\Weather and Pollution\\Data\\Raw\\OW_raw_pollution_data.json'\n",
    "with open(OW_raw_pollution_filepath) as f:\n",
    "    raw_pollution_data = json.load(f)\n",
    "flattened_pollution_data = [flatten(item) for item in raw_pollution_data]\n",
    "\n",
    "pollution_data_df = pd.DataFrame(flattened_pollution_data)\n",
    "\n",
    "# Define a mapping for column renaming and data type conversions\n",
    "pollution_column_map = {\n",
    "    'city_id$int': ('city_id', 'int'),\n",
    "    'list.[0].dt$int': ('date_time', 'datetime'),\n",
    "    'longitude$float': ('longitude', 'float'),\n",
    "    'latitude$float': ('latitude', 'float'),\n",
    "    'list.[0].main.aqi$int': ('aqi', 'int'),\n",
    "    'list.[0].components.co$float': ('co', 'float'),\n",
    "    'list.[0].components.no$int': ('no', 'floT'),\n",
    "    'list.[0].components.no2$float': ('no2', 'float'),\n",
    "    'list.[0].components.o3$float': ('o3', 'float'),\n",
    "    'list.[0].components.so2$float': ('so2', 'float'),\n",
    "    'list.[0].components.pm2_5$float': ('pm2_5', 'float'),\n",
    "    'list.[0].components.pm10$float': ('pm10', 'float'),\n",
    "    'list.[0].components.nh3$float': ('nh3', 'float')\n",
    "}\n",
    "\n",
    "# Rename columns and convert data types\n",
    "pollution_data_df = rename_and_convert_columns(pollution_data_df, pollution_column_map)\n",
    "\n",
    "# Define the columns to keep\n",
    "required_pollution_columns = [col for col in pollution_column_map.values() if col[0] in pollution_data_df.columns]\n",
    "\n",
    "# Filter DataFrame to keep only the required columns\n",
    "pollution_data_df = pollution_data_df[[col[0] for col in required_pollution_columns]]\n",
    "pollution_data_df['local_time'] = pollution_data_df.apply(\n",
    "    lambda row: calculate_local_time(row['date_time'], row['latitude'], row['longitude']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "pollution_data_df=pollution_data_df.drop(columns=['latitude','longitude'])\n",
    "\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "pollution_data_df.to_csv('pollution_data_df.csv', index=False)\n",
    "\n",
    "print(pollution_data_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load all credentials \n",
    "with open(rf'C:\\Users\\gurpr\\OneDrive\\Documents\\New Projects\\Weather and Pollution\\Data_ETL\\config.json') as config_file:\n",
    "    config = json.load(config_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "OW_api_key = config['OW_api_key']\n",
    "db_name = config['db_name']\n",
    "db_user = config['user']\n",
    "db_pass = config['password']\n",
    "\n",
    "engine = create_engine(f'postgresql+psycopg2://{db_user}:{db_pass}\\\n",
    "@localhost/{db_name}')\n",
    "\n",
    "conn = engine.connect()\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "# Define paths for saving CSV files with timestamps\n",
    "weather_csv_path = rf'D:\\Datasets\\Weather and Pollution\\Data\\Failed to Upload data\\Weather\\weather_data_{timestamp}.csv'\n",
    "pollution_csv_path = rf'D:\\Datasets\\Weather and Pollution\\Data\\Failed to Upload data\\Pollution\\pollution_data_{timestamp}.csv'\n",
    "\n",
    "try:\n",
    "    weather_data_df.to_sql('weather', con=conn, if_exists='append', index=False)\n",
    "\n",
    "except Exception as e:\n",
    "    weather_data_df.to_csv(weather_csv_path, index=False)\n",
    "\n",
    "try:\n",
    "    pollution_data_df.to_sql('pollution', con=conn, if_exists='append', index=False)\n",
    "\n",
    "except Exception as e:\n",
    "    pollution_data_df.to_csv(pollution_csv_path, index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection failed: (psycopg2.OperationalError) connection to server at \"localhost\" (::1), port 5432 failed: fe_sendauth: no password supplied\n",
      "\n",
      "(Background on this error at: https://sqlalche.me/e/14/e3q8)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Database connection details\n",
    "db_name = config['db_name']\n",
    "db_user = config['user']\n",
    "db_pass = config['password']\n",
    "db_host = config['host']\n",
    "db_port = config['port']\n",
    "# Create the SQLAlchemy engine\n",
    "engine = create_engine(f'postgresql+psycopg2://{db_user}:{db_pass}\\\n",
    "@{db_host}:{db_port}/{db_name}')\n",
    "\n",
    "\n",
    "# Function to test the connection\n",
    "def test_connection():\n",
    "    try:\n",
    "        # Establish a connection using a context manager\n",
    "        with engine.connect() as connection:\n",
    "            print(\"Connection successful!\")\n",
    "            # Execute a simple query to verify connection\n",
    "            result = connection.execute(\"SELECT 1\")\n",
    "            print(\"Query result:\", result.fetchone())\n",
    "    except Exception as e:\n",
    "        print(\"Connection failed:\", e)\n",
    "\n",
    "# Test the connection\n",
    "test_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define paths for saving CSV files with timestamps\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "weather_csv_path = rf'D:\\Datasets\\Weather and Pollution\\Data\\Failed to Upload data\\Weather\\weather_data_{timestamp}.csv'\n",
    "pollution_csv_path = rf'D:\\Datasets\\Weather and Pollution\\Data\\Failed to Upload data\\Pollution\\pollution_data_{timestamp}.csv'\n",
    "\n",
    "try:\n",
    "    # Use the engine directly in to_sql\n",
    "    weather_data_df.to_sql('weather', con=engine, if_exists='append', index=False)\n",
    "    print(\"Successfully uploaded weather data.\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to upload weather data: {e}\")\n",
    "    weather_data_df.to_csv(weather_csv_path, index=False)\n",
    "\n",
    "try:\n",
    "    # Use the engine directly in to_sql\n",
    "    pollution_data_df.to_sql('pollution', con=engine, if_exists='append', index=False)\n",
    "    print(\"Successfully uploaded pollution data.\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to upload pollution data: {e}\")\n",
    "    pollution_data_df.to_csv(pollution_csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
